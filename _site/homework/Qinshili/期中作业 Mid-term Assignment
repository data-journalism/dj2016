# -*- coding: utf-8 -*-
"""
Created on Tue Nov  8 13:12:00 2016

@author: jasmine
"""

import urllib2
from bs4 import BeautifulSoup
from selenium import webdriver
import os

def get_list(list, url):
    try:
        content = urllib2.urlopen(url).read()
        soup = BeautifulSoup(content, "html.parser")
        print "finish getting"
        articles = soup.find_all('td')     
        for i in articles:
            name = "http://gbzl.people.com.cn/" + i.a['href']
            print name
            list.append(name)
    except:
        pass

    return list
    
def get_info(list):
    fl = open('details.txt', 'a')

    ENCODE = 'utf-8'  
    time = 1
    for i in list:
        print time  
        time += 1
        try:
            content = urllib2.urlopen(i).read()
            soup = BeautifulSoup(content, "html.parser")
            url = soup.text

            if url.startswith("location"):
                url = url[15:len(soup) - 3]
                con = urllib2.urlopen(url).read()
                soup = BeautifulSoup(con, "html.parser")

            name = soup.find('strong').text
            name = name.encode(ENCODE)
            experience = soup.find('p').text
            experience = experience.encode(ENCODE)
            fl.write(name + " ")
            fl.write(experience + " ")
            ul = soup.find_all('li', limit=8)
            for li in ul:
                txt = li.text.encode(ENCODE)
                fl.write(txt + " ")
            fl.write('\n')

            
            mainExp = soup.find('p', 'jili').text.encode(ENCODE);
            fl.write(mainExp)
            fl.write('\n')
            fl.write('\n')

        except Exception, e:
            print repr(e)

    fl.close()


if __name__ == "__main__":
    url = "http://cpc.people.com.cn/gbzl/flcx.html"
    list = []
    list = get_list(list, url)

    get_info(list)
